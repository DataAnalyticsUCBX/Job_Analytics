{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-77663c8b54ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m##NS Packages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeocoders\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNominatim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgmaps\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'geopy'"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "\n",
    "##NS Packages\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "import gmaps\n",
    "import gmaps.datasets\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import squarify\n",
    "\n",
    "\n",
    "color = (65/255,174/255,189/255)\n",
    "treemap_size = (20,20)\n",
    "wordcloud_size = (30,15)\n",
    "barchart_size = (30,15)\n",
    "fontvalue = 20\n",
    "\n",
    "Aijobsindustry_dataset = pd.read_csv(\"AIJobsIndustry_Clean_v3.csv\")\n",
    "print(f\"No of rows in Aijobsindustry_dataset is {Aijobsindustry_dataset.shape[0]}\")\n",
    "\n",
    "Dice_us_jobs_dataset = pd.read_csv(\"Dice_US_jobs_Clean_v4.csv\", encoding=\"cp437\")\n",
    "print(f\"No of rows in Dice_us_jobs_dataset is {Dice_us_jobs_dataset.shape[0]}\")\n",
    "\n",
    "monster_dataset = pd.read_csv(\"Monster_Clean.csv\")\n",
    "print(f\"No of rows in monster_dataset is {monster_dataset.shape[0]}\")\n",
    "\n",
    "indeed_dataset = pd.read_csv(\"alldata_Clean_v3.csv\")\n",
    "print(f\"No of rows in indeed_dataset is {indeed_dataset.shape[0]}\")\n",
    "\n",
    "multi_src_dataset = pd.read_csv(\"cleanedandfilteredUSJobs.csv\")\n",
    "print(f\"No of rows in multiple source data set is {multi_src_dataset.shape[0]}\")\n",
    "\n",
    "dice_tech_filtered = pd.read_csv(\"Dice_US_Tech_FilteredJobData.csv\")\n",
    "print(f\"No of rows in dice_tech_filtered is {dice_tech_filtered.shape[0]}\")\n",
    "\n",
    "print(f\"No of rows in final merged data set should be {Aijobsindustry_dataset.shape[0]+multi_src_dataset.shape[0]+Dice_us_jobs_dataset.shape[0]+monster_dataset.shape[0]+indeed_dataset.shape[0]+dice_tech_filtered.shape[0]}\")\n",
    "\n",
    "#list that puts all the files open into a list that will be used in the concat function\n",
    "datasets_to_merge = [Aijobsindustry_dataset,Dice_us_jobs_dataset,monster_dataset,indeed_dataset,dice_tech_filtered,multi_src_dataset]\n",
    "\n",
    "#concat function to concat all the datatables to one\n",
    "merged_dataset = pd.concat(datasets_to_merge, sort=False)\n",
    "print(f\"Actual no of rows in merged_dataset is {merged_dataset.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset.to_csv(\"final_dataframe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_list =['data analysis','machine learning','statistics','computer science','communication','mathematics', 'visualization', 'ai',\\\n",
    "             'deep learning', 'nlp', 'software development','neural networks', 'project management', 'software engineering', \\\n",
    "              'data engineering','bi','modeling','etl','statistical analysis','research','deep learning','interpersonal skills',\\\n",
    "            'web scraping','neural network','decision tree','random forest','testing']\n",
    "tool_list = ['python','r','sql','hadoop','spark','java','sas','tableau','hive','scala','aws','c++','matlab',\\\n",
    "             'c','excel','nosql','linux','vba','json','numpy','pandas','matplotlib','api','mysql','mongodb','html','css',\\\n",
    "             'java script','ajax','d3','leaflet','matlab']\n",
    "edu_list = ['bachelor','bachelors','master','masters','phd','post graduation','graduation','high school','bs','ms','ba','ma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viv - the code can be improved to bring effeciency and can have a function to do the reg expression, howver for now use this and we can make improvements later\n",
    "description = merged_dataset['Description']\n",
    "skills = merged_dataset['Skills']\n",
    "title = merged_dataset['Position']\n",
    "desc_skills = description.append(skills)\n",
    "parse_list = description.append(title)\n",
    "skill_count = {}\n",
    "tool_count = {}\n",
    "edu_count = {}\n",
    "no_edu_count = 0\n",
    "for entry in parse_list:\n",
    "    try:\n",
    "        entry = re.sub('[./\\n\\r(),:-]', ' ', str(entry))\n",
    "#        print(entry)\n",
    "        entry = re.sub('[^A-Za-z0-9+ ]', '', str(entry)).lower()\n",
    "        entry = re.sub('data analytics', 'data analysis', str(entry))\n",
    "        entry = re.sub('artificial intelligence', 'ai', str(entry))\n",
    "#        print(entry)\n",
    "        for skill in skill_list:\n",
    "            if (f' {skill} ' in f' {entry} '):\n",
    "                if skill not in skill_count:\n",
    "                    skill_count[skill] = 1\n",
    "                else:\n",
    "                    skill_count[skill] += 1\n",
    "        for tool in tool_list:\n",
    "            if f' {tool} ' in f' {entry} ':\n",
    "                if tool not in tool_count:\n",
    "                    tool_count[tool] = 1\n",
    "                else:\n",
    "                    tool_count[tool] += 1   \n",
    "    except:\n",
    "        print(\"Skipping an entry due to bad data\")\n",
    "        continue\n",
    "description2 = merged_dataset['Description']\n",
    "for item in description2:\n",
    "    try:\n",
    "        item = re.sub('[./\\n\\r(),:-]', ' ', str(item))\n",
    "        item = re.sub('[^A-Za-z0-9+ ]', '', str(item)).lower()\n",
    "        item = re.sub('data analytics', 'data analysis', str(item))\n",
    "        item = re.sub('artificial intelligence', 'ai', str(item))\n",
    "        i = 0\n",
    "        for edu in edu_list:\n",
    "            if f' {edu} ' in f' {item} ':\n",
    "                if edu not in edu_count:\n",
    "                    edu_count[edu] = 1\n",
    "                else:\n",
    "                    edu_count[edu] += 1 \n",
    "            else:\n",
    "                i +=1\n",
    "        if i==12: \n",
    "            no_edu_count +=1\n",
    "    except:\n",
    "        print(\"Skipping an entry due to bad data\")\n",
    "        continue\n",
    "print(skill_count)\n",
    "print(tool_count)\n",
    "print(edu_count)\n",
    "education_count = {\n",
    "    'High School':edu_count['high school'],\n",
    "    'Bachelors':edu_count['bachelors']+edu_count['bachelor']+edu_count['graduation']+edu_count['bs']+edu_count['ba'],\n",
    "    'Masters':edu_count['masters']+edu_count['master']+edu_count['post graduation']+edu_count['ms']+edu_count['ma'],\n",
    "    'Phd':edu_count['phd'],\n",
    "    'No education mentioned':no_edu_count\n",
    "}\n",
    "print(education_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://amueller.github.io/word_cloud/generated/wordcloud.WordCloud.html\n",
    "#wordcloud documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strip space to remove any miss match of state text\n",
    "merged_dataset[\"Loc_state\"] = merged_dataset[\"Loc_state\"].str.strip()\n",
    "merged_dataset\n",
    "merged_dataset_stacked_bar = merged_dataset\n",
    "#create a long string from the description column to feed into wordcloud\n",
    "desc = merged_dataset['Description']\n",
    "desc = \" \".join((str(x) for x in desc))\n",
    "#create the wordcloud using the string and add formating for size\n",
    "wordcloud = WordCloud(scale=3,relative_scaling=1).generate(desc)\n",
    "plt.figure(figsize=wordcloud_size)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"graphs/DescWordCloud.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordcloud.process_text(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define skills column to a new handle and create a long string from skills column\n",
    "skills_col = merged_dataset[\"Skills\"]\n",
    "skills_col = \"\".join((str(x) for x in skills_col))\n",
    "skills_col\n",
    "#create wordcloud with the new string and save and show\n",
    "wordcloud = WordCloud(max_font_size=100,scale=3,relative_scaling=1).generate(skills_col)\n",
    "plt.figure(figsize=wordcloud_size)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"graphs/SkillsWordCloud.jpg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped by state to create a bar graph and pie chart to get an idea of distribution of the jobs by state\n",
    "group_by_state = merged_dataset.groupby(\"Loc_state\")\n",
    "#apply aggrigrate function of count to get number of count per state and remove the extra columns to end up with counters per state\n",
    "count_for_state = group_by_state.count()\n",
    "count_for_state = count_for_state[\"Position\"]\n",
    "count_for_state = count_for_state.to_frame()\n",
    "count_for_state = count_for_state.reset_index()\n",
    "#set index of loc state for setting axies for bar and pie\n",
    "count_for_state = count_for_state.set_index(\"Loc_state\")\n",
    "print(count_for_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#states to check against\n",
    "states = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AS': 'American Samoa',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DC': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'GU': 'Guam',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MP': 'Northern Mariana Islands',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NA': 'National',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'PR': 'Puerto Rico',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop to check against the 50 states of US, and drop non relevant ones\n",
    "found = []\n",
    "notfound = []\n",
    "\n",
    "for item in count_for_state.index.values.tolist():\n",
    "    try:\n",
    "        if states[item]:\n",
    "#             print(f\"Found state: {item}\")\n",
    "            found.append(item)\n",
    "    except:\n",
    "        notfound.append(item)\n",
    "        print(f\"The {item} is not a US state.\")\n",
    "        count_for_state.drop(item, axis= 0,inplace = True)\n",
    "        print(f\"Dropped column for {item}\")\n",
    "        \n",
    "print(f\"Found: {len(found)} of states\")\n",
    "print(f\"Did not find:{notfound}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_for_state\n",
    "count_for_state = count_for_state.sort_values(\"Position\", ascending=False)\n",
    "count_for_state_store = count_for_state\n",
    "count_for_state.plot.bar(figsize=barchart_size,legend=False, color = color, zorder=2.5)\n",
    "plt.xticks(rotation=90,size=fontvalue)\n",
    "plt.yticks(size=fontvalue)\n",
    "plt.title(\"Job Count by State\")\n",
    "plt.xlabel(\"States\",size=fontvalue)\n",
    "plt.ylabel(\"Count of Jobs\",size=fontvalue)\n",
    "plt.grid(linestyle='-', linewidth='0.5', color='red', axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/BarOfCountofJobsUS.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_for_cities =[\"salmon\",\"green\",\"lightsteelblue\",\"lightsteelblue\",\"goldenrod\",\"teal\",\"goldenrod\",\"sienna\",\"plum\",\"goldenrod\"]\n",
    "merged_dataset_stacked_bar_grouped = merged_dataset_stacked_bar.groupby([\"Loc_state\",\"Loc_city\"])\n",
    "merged_dataset_stacked_bar_grouped_count = merged_dataset_stacked_bar_grouped.count()\n",
    "merged_dataset_stacked_bar_grouped_count = merged_dataset_stacked_bar_grouped_count[\"Position\"]\n",
    "merged_dataset_stacked_bar_grouped_count\n",
    "merged_dataset_stacked_bar_grouped_count_sorted = merged_dataset_stacked_bar_grouped_count.sort_values(ascending=False)\n",
    "# merged_dataset_stacked_bar_grouped_count_sorted = merged_dataset_stacked_bar_grouped_count.sort_values()\n",
    "merged_dataset_stacked_bar_grouped_count_sorted\n",
    "merged_dataset_stacked_bar_grouped_count_sorted_head = merged_dataset_stacked_bar_grouped_count_sorted.head(10)\n",
    "merged_dataset_stacked_bar_grouped_count_sorted_head.plot.bar(figsize=barchart_size,stacked=True, color=color,zorder=2.5)\n",
    "# merged_dataset_stacked_bar_grouped_count_sorted_head.plot.bar(figsize=(30,15),stacked=True, color=color)\n",
    "plt.grid(linestyle='-', linewidth='0.5', color='red', axis='y')\n",
    "plt.xticks(rotation=90, size = fontvalue)\n",
    "plt.yticks(size=fontvalue)\n",
    "merged_dataset_stacked_bar_grouped_count_sorted_head\n",
    "plt.title(\"Top 10 Cities across US\",size = fontvalue)\n",
    "plt.xlabel(\"States_City\",size = fontvalue)\n",
    "plt.ylabel(\"Count of Jobs\",size = fontvalue)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/BarOfStateandCities.jpg\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "california_data_set = merged_dataset.loc[merged_dataset[\"Loc_state\"] == \"CA\"]\n",
    "california_data_set\n",
    "california_data_set_grouped_by_city = california_data_set.groupby(\"Loc_city\")\n",
    "count_for_california = california_data_set_grouped_by_city.count()\n",
    "count_for_california = count_for_california[\"Position\"]\n",
    "count_for_california = count_for_california.to_frame()\n",
    "# count_for_california = count_for_california.reset_index()\n",
    "count_for_california\n",
    "count_for_california = count_for_california.sort_values([\"Position\"], ascending=False )\n",
    "count_for_california\n",
    "# fig = plt.figure(figsize=(60,10))\n",
    "count_for_california.plot.bar(figsize=(11.20*3,4*4),legend=False, color=color,zorder=2.5)\n",
    "# count_for_california.plot.bar(x = count_for_california[\"Loc_city\"], y = [\"Position\"].sort_values(ascending=False))\n",
    "# # plt.bar(count_for_california[\"Loc_city\"],count_for_california[\"Position\"], align='center', width=0.5,)\n",
    "\n",
    "plt.xticks(rotation=90,size=fontvalue)\n",
    "plt.yticks(size=fontvalue)\n",
    "plt.title(\"Job Count in California Cities\",size = fontvalue)\n",
    "plt.xlabel(\"Cities\",size = fontvalue )\n",
    "plt.ylabel(\"Count of Jobs\",size = fontvalue)\n",
    "\n",
    "#Labels\n",
    "# for i, v in enumerate(count_for_california[\"Position\"]):\n",
    "# #     print(f\"value of i: {i}, value of v: {v}\")\n",
    "#     plt.text(i - .2, v + 1 , str(v), color='black', fontweight='bold')\n",
    "plt.grid(linestyle='-', linewidth='0.5', color='red',axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/BarOfCountofJobsCA.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count_for_california = count_for_california.sort_values([\"Position\"], ascending=False )\n",
    "# count_for_california = count_for_california.set_index(\"Loc_city\")\n",
    "# count_for_california\n",
    "count_for_california_top10 = count_for_california[0:10]\n",
    "count_for_california_top10\n",
    "\n",
    "count_for_california_top10.plot.bar(figsize=barchart_size,legend=False, color=color,zorder=2.5)\n",
    "# count_for_california.plot.bar(x = count_for_california[\"Loc_city\"], y = [\"Position\"].sort_values(ascending=False))\n",
    "# # plt.bar(count_for_california[\"Loc_city\"],count_for_california[\"Position\"], align='center', width=0.5,)\n",
    "\n",
    "plt.xticks(rotation=90,size=fontvalue)\n",
    "plt.yticks(size=fontvalue)\n",
    "\n",
    "plt.title(\"Top 10 California Cities\",size = fontvalue)\n",
    "plt.xlabel(\"Cities\",size = fontvalue )\n",
    "plt.ylabel(\"Count of Jobs\",size = fontvalue)\n",
    "\n",
    "# sortedvalue = count_for_california[\"Position\"].sort_values(ascending=False)\n",
    "# for i, v in enumerate(count_for_california_top10[\"Position\"]):\n",
    "# #     print(f\"value of i: {i}, value of v: {v}\")\n",
    "#     plt.text(i - .2, v + 1 , str(v), color='black', fontweight='bold')\n",
    "\n",
    "plt.grid(linestyle='-', linewidth='0.5', color='red', axis='y',zorder=2.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/BarOfCountofJobsCA_top10.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_for_state = count_for_state.reset_index()\n",
    "\n",
    "plt.figure(figsize=treemap_size)\n",
    "squarify.plot(sizes=count_for_state[\"Position\"].head(10), label =count_for_state[\"Loc_state\"].head(10), alpha =.7,color=[\"red\",\"green\",\"blue\", \"grey\",\"plum\",\"crimson\",\"silver\",\"tan\",\"cyan\",\"skyblue\"])\n",
    "# plt.pie(count_for_state[\"Position\"].head(10), labels=count_for_state[\"Loc_state\"].head(10),rotatelabels=True, autopct=make_autopct(count_for_state[\"Position\"]),labeldistance=1.1)\n",
    "# plt.savefig(\"PieOfCountofJobsUS.jpg\")\n",
    "plt.title(\"Top 10 States in US\", size = fontvalue)\n",
    "# plt.rc('font', size=fontvalue)\n",
    "plt.xticks(size=fontvalue)\n",
    "plt.yticks(size=fontvalue)\n",
    "# plt.rc('legend',fontsize=fontvalue )\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/TreeMapofTop10states.jpg\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PieChart\n",
    "def make_autopct(values):\n",
    "    def my_autopct(pct):\n",
    "        total = sum(values)\n",
    "        val = int(round(pct*total/100.0))\n",
    "        return '{p:.2f}%  ({v:d})'.format(p=pct,v=val)\n",
    "    return my_autopct\n",
    "# count_for_state = count_for_state.reset_index()\n",
    "plt.figure(figsize=[30,15])\n",
    "\n",
    "plt.pie(count_for_state[\"Position\"].head(10), labels=count_for_state[\"Loc_state\"].head(10),rotatelabels=True, autopct=make_autopct(count_for_state[\"Position\"]),labeldistance=1.1)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/PieOfCountofJobsUS.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(title)\n",
    "job_type = ['administrator','tester','coordinator','designer','engineer','modeler',\\\n",
    "           'product manager','program manager','project manager','researcher','system analyst','analyst','scientist','developer']\n",
    "job_level = ['senior','midlevel','junior']\n",
    "job_type_count = {}\n",
    "job_level_count = {}\n",
    "for entry in title:\n",
    "   try:\n",
    "       #substituting job_types with meaningful names\n",
    "       entry = re.sub('[./\\n\\r(),:-]', ' ', str(entry))\n",
    "       entry = re.sub('[^A-Za-z0-9+ ]', '', str(entry)).lower()\n",
    "       entry = re.sub('(admin)', 'administrator', str(entry))\n",
    "       entry = re.sub('(analysis|analytical|analytics)', 'analyst', str(entry))\n",
    "       entry = re.sub('(design)', 'designer', str(entry))\n",
    "       entry = re.sub('(dev|developers|devops|programmer)', 'developer', str(entry))\n",
    "       entry = re.sub('(engineering|engineerscientist)', 'engineer', str(entry))\n",
    "       entry = re.sub('(modeler)', 'modeler', str(entry))\n",
    "#         entry = re.sub('(product)', 'product manager', str(entry))\n",
    "#         entry = re.sub('(program)', 'program manager', str(entry))\n",
    "#         entry = re.sub('(project)', 'project manager', str(entry))\n",
    "       entry = re.sub('(research)', 'researcher', str(entry))\n",
    "       entry = re.sub('(science|sciences|scientific|scientistengineer)', 'scientist', str(entry))\n",
    "       entry = re.sub('(system|systems)', 'system analyst', str(entry))\n",
    "       entry = re.sub('(automation|qa)', 'tester', str(entry))\n",
    "       #substituting job levels with meaningful names\n",
    "       entry = re.sub('(associate|intern|assistant|jr|assistant|entry|student)', 'junior', str(entry))\n",
    "       entry = re.sub('(manager|lead|architect|program|mid|manager|mgr)', 'midlevel', str(entry))\n",
    "       entry = re.sub('(sr|director|principal|executive|vp|president|chief|vice)', 'senior', str(entry))\n",
    "       for type in job_type:\n",
    "           if (f' {type} ' in f' {entry} '):\n",
    "               if type not in job_type_count:\n",
    "                   job_type_count[type] = 1\n",
    "               else:\n",
    "                   job_type_count[type] += 1\n",
    "               for level in job_level:\n",
    "                   if f' {level} ' in f' {entry} ':\n",
    "                       job_type_level = type+'_'+level\n",
    "                       if job_type_level not in job_level_count:\n",
    "                           job_level_count[job_type_level] = 1\n",
    "                       else:\n",
    "                           job_level_count[job_type_level] += 1\n",
    "   except:\n",
    "       print(\"Skipping an entry due to bad data\")\n",
    "       continue\n",
    "print(job_type_count)\n",
    "print(job_level_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_bar_frame =pd.DataFrame({\"Job\":[],\n",
    "                               \"senior\":[],\n",
    "                              \"midlevel\":[],\n",
    "                              \"junior\":[]})\n",
    "for job in job_type_count:\n",
    "    senior_count = 0\n",
    "    midlevel_count = 0\n",
    "    junior_count = 0\n",
    "#     print(job)    \n",
    "    for lvl in job_level_count:\n",
    "        to_check = lvl.split(\"_\")\n",
    "        if job == to_check[0]:\n",
    "#             print(to_check)\n",
    "            if to_check[1] == \"midlevel\":\n",
    "                midlevel_count = job_level_count[lvl]\n",
    "            if to_check[1] == \"junior\":\n",
    "                junior_count = job_level_count[lvl]\n",
    "            if to_check[1] == \"senior\":\n",
    "                senior_count = job_level_count[lvl]     \n",
    "    toappend={\"Job\":job,\n",
    "                  \"senior\":senior_count,\n",
    "                  \"midlevel\":midlevel_count,\n",
    "                  \"junior\":junior_count}\n",
    "#     print(toappend)\n",
    "    stack_bar_frame = stack_bar_frame.append(toappend,ignore_index=True)\n",
    "#         print(lvl)\n",
    "#     stack_bar_frame[items] = job_type_count[items]\n",
    "#     stack_bar_frame\n",
    "#     print(items)\n",
    "# #     print(job_type_count[items])\n",
    "# stack_bar_frame[\"total\"] = job_type_count[\"\"] \n",
    "job_type_count\n",
    "\n",
    "stack_bar_frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_type_count_frame = pd.DataFrame.from_dict([job_type_count]).T.reset_index()\n",
    "job_type_count_frame = job_type_count_frame.rename(columns={0:\"Total\",\"index\":\"Job\"})\n",
    "# job_type_count\n",
    "stacked_bar_merged_frame = job_type_count_frame.merge(stack_bar_frame, how=\"inner\", on=\"Job\")\n",
    "stacked_bar_merged_frame[\"other\"] = stacked_bar_merged_frame[\"Total\"] - (stacked_bar_merged_frame[\"senior\"]+stacked_bar_merged_frame[\"midlevel\"]+stacked_bar_merged_frame[\"junior\"])\n",
    "\n",
    "stacked_bar_merged_frame[[\"senior\",\"midlevel\",\"junior\",\"Total\"]].astype(int)\n",
    "stacked_bar_merged_frame.dtypes\n",
    "stacked_bar_merged_frame = stacked_bar_merged_frame.set_index(\"Job\")\n",
    "stacked_bar_merged_frame = stacked_bar_merged_frame.sort_values(by=\"Total\", ascending= False)\n",
    "stacked_bar_merged_frame_top = stacked_bar_merged_frame.head(4)\n",
    "stacked_bar_merged_frame_top = stacked_bar_merged_frame_top[[\"senior\",\"midlevel\",\"junior\",\"other\"]]\n",
    "stacked_bar_merged_frame_top.plot.bar(figsize=barchart_size,stacked = True)\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=90,size=fontvalue)\n",
    "plt.yticks(size=fontvalue)\n",
    "plt.xlabel(\"Job Title\",size = fontvalue)\n",
    "plt.ylabel(\"Count\", size = fontvalue)\n",
    "plt.tight_layout()\n",
    "plt.legend(fontsize = fontvalue)\n",
    "plt.savefig(\"graphs/StackedBarOfJobTypesTop4.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_type_count_frame = pd.DataFrame.from_dict([job_type_count]).T.reset_index()\n",
    "job_type_count_frame = job_type_count_frame.rename(columns={0:\"Total\",\"index\":\"Job\"})\n",
    "# job_type_count\n",
    "stacked_bar_merged_frame = job_type_count_frame.merge(stack_bar_frame, how=\"inner\", on=\"Job\")\n",
    "stacked_bar_merged_frame[\"other\"] = stacked_bar_merged_frame[\"Total\"] - (stacked_bar_merged_frame[\"senior\"]+stacked_bar_merged_frame[\"midlevel\"]+stacked_bar_merged_frame[\"junior\"])\n",
    "\n",
    "stacked_bar_merged_frame[[\"senior\",\"midlevel\",\"junior\",\"Total\"]].astype(int)\n",
    "stacked_bar_merged_frame.dtypes\n",
    "stacked_bar_merged_frame = stacked_bar_merged_frame.set_index(\"Job\")\n",
    "# stacked_bar_merged_frame = stacked_bar_merged_frame.T\n",
    "# stacked_bar_merged_frame = stacked_bar_merged_frame[[\"senior\",\"midlevel\",\"junior\",\"other\"]]\n",
    "# stacked_bar_merged_frame\n",
    "# stacked_bar_merged_frame.plot.bar(stacked = True)\n",
    "# stacked_bar_merged_frame\n",
    "stacked_bar_merged_frame = stacked_bar_merged_frame.sort_values(by=\"Total\", ascending= True)\n",
    "stacked_bar_merged_frame_top = stacked_bar_merged_frame.head(11-4)\n",
    "stacked_bar_merged_frame_top = stacked_bar_merged_frame_top[[\"senior\",\"midlevel\",\"junior\",\"other\"]]\n",
    "stacked_bar_merged_frame_top.plot.bar(figsize=barchart_size,stacked = True)\n",
    "plt.xticks(rotation=90,size=fontvalue)\n",
    "plt.yticks(size=fontvalue)\n",
    "plt.xlabel(\"Job Title\",size = fontvalue)\n",
    "plt.ylabel(\"Count\", size = fontvalue)\n",
    "plt.tight_layout()\n",
    "plt.legend(fontsize = fontvalue)\n",
    "plt.savefig(\"graphs/StackedBarOfJobTypessmallgroup.jpg\")\n",
    "plt.show()\n",
    "# print(len(stacked_bar_merged_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#StackedBar Graph\n",
    "\n",
    "top_10_states = count_for_state.head(10)\n",
    "merged_dataset_stacked_bar_grouped_count_framed = merged_dataset_stacked_bar_grouped_count.to_frame()\n",
    "merged_dataset_stacked_bar_grouped_count_framed = merged_dataset_stacked_bar_grouped_count_framed.reset_index()\n",
    "joined_frame = merged_dataset_stacked_bar_grouped_count_framed.merge(top_10_states, on =\"Loc_state\", how=\"right\")\n",
    "ca_frame = joined_frame.loc[joined_frame[\"Loc_state\"] == \"CA\"]\n",
    "ca_frame = ca_frame[[\"Loc_state\",\"Loc_city\",\"Position_x\",\"Position_y\"]].sort_values(by = \"Position_x\", ascending=False)\n",
    "new_frame = ca_frame.head(5)\n",
    "new_frame\n",
    "difference = new_frame[\"Position_y\"].max() - new_frame[\"Position_x\"].sum()\n",
    "toappend = [{\"Loc_state\":\"CA\",\n",
    "            \"Loc_city\": \"Other\",\n",
    "            \"Position_x\": difference,\n",
    "           \"Position_y\":new_frame[\"Position_y\"].max()}]\n",
    "new_frame = new_frame.append(toappend, ignore_index=True).sort_values(by =\"Position_x\",ascending=False)\n",
    "new_frame\n",
    "new_frame = new_frame.pivot(index = \"Loc_state\", columns= \"Loc_city\", values = \"Position_x\")\n",
    "new_frame\n",
    "new_frame.plot.bar(stacked= True,legend=True)\n",
    "\n",
    "\n",
    "\n",
    "##MISC FOR NY\n",
    "# ny_frame = joined_frame.loc[joined_frame[\"Loc_state\"] == \"NY\"]\n",
    "# ca_frame = ca_frame.set_index([\"Loc_state\",\"Loc_city\"])\n",
    "# ny_frame = ny_frame[[\"Loc_state\",\"Loc_city\",\"Position_x\",\"Position_y\"]].sort_values(by = \"Position_x\", ascending=False)\n",
    "# # ca_frame.dtypes\n",
    "# ca_frame.head(10).plot.bar(x = \"Loc_city\",stacked = True, legend=False)\n",
    "# plt.show()\n",
    "# new1_frame = ny_frame.head(5)\n",
    "# new1_frame\n",
    "# difference = new1_frame[\"Position_y\"].max() - new1_frame[\"Position_x\"].sum()\n",
    "# toappend = [{\"Loc_state\":\"NY\",\n",
    "#             \"Loc_city\": \"Other\",\n",
    "#             \"Position_x\": difference,\n",
    "#            \"Position_y\":new1_frame[\"Position_y\"].max()}]\n",
    "# new1_frame = new1_frame.append(toappend, ignore_index=True).sort_values(by =\"Position_x\",ascending=False)\n",
    "# new1_frame\n",
    "# new1_frame = new1_frame.pivot(index = \"Loc_state\", columns= \"Loc_city\", values = \"Position_x\")\n",
    "# new1_frame\n",
    "# new1_frame.plot.bar(stacked= True,legend=False)\n",
    "\n",
    "# plt.show()\n",
    "# merged_dataset_stacked_bar_grouped = merged_dataset_stacked_bar.groupby([\"Loc_state\",\"Loc_city\"])\n",
    "# # merged_dataset_stacked_bar_grouped_count = merged_dataset_stacked_bar_grouped.count()\n",
    "# # merged_dataset_stacked_bar_grouped_count = merged_dataset_stacked_bar_grouped_count[\"Position\"]\n",
    "\n",
    "# merged_dataset_stacked_bar_grouped_count_sorted = merged_dataset_stacked_bar_grouped_count.sort_values(ascending=False)\n",
    "# merged_dataset_stacked_bar_grouped_count_sorted_head = merged_dataset_stacked_bar_grouped_count_sorted.head(10)\n",
    "# merged_dataset_stacked_bar_grouped_count_sorted_head\n",
    "\n",
    "##Not a good way to display this type of data, since all the legends for each state will be different => too complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=wordcloud_size)\n",
    "wordcloud = WordCloud(scale=3,relative_scaling=.5).generate_from_frequencies(tool_count)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/ToolsTargetedWordCloud.jpg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_for_state = count_for_state_store\n",
    "# count_for_state_total = count_for_state[\"Position\"].sum()\n",
    "# count_for_state_total\n",
    "# top10_states_total = count_for_state[\"Position\"].head(10).sum()\n",
    "# top10_states_total\n",
    "# top10_others = count_for_state_total - top10_states_total\n",
    "# top10_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skill_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=wordcloud_size)\n",
    "wordcloud = WordCloud(scale=3,relative_scaling=1).generate_from_frequencies(skill_count)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/SkillsTargetedWordCloud.jpg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=wordcloud_size)\n",
    "wordcloud = WordCloud(scale=3,relative_scaling=1).generate_from_frequencies(tool_count)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/ToolsTargetedWordCloud.jpg\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=wordcloud_size)    \n",
    "wordcloud = WordCloud(scale=3).generate_from_frequencies(education_count)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/EduTargetedWordCloud.jpg\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
