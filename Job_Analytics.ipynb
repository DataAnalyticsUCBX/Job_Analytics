{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "No of rows in Aijobsindustry_dataset is 631\n",
      "No of rows in Dice_us_jobs_dataset is 1265\n",
      "No of rows in monster_dataset is 162\n",
      "No of rows in indeed_dataset is 6953\n",
      "No of rows in dice_tech_filtered is 1566\n",
      "No of rows in final merged data set should be 10577\n",
      "Actual no of rows in merged_dataset is 10577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\excep\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "# import gmplot\n",
    "# from geopy.geocoders import Nominatim\n",
    "# import time\n",
    "# import gmaps\n",
    "# import gmaps.datasets\n",
    "\n",
    "Aijobsindustry_dataset = pd.read_csv(\"AIJobsIndustry_Clean_v3.csv\")\n",
    "print(f\"No of rows in Aijobsindustry_dataset is {Aijobsindustry_dataset.shape[0]}\")\n",
    "\n",
    "Dice_us_jobs_dataset = pd.read_csv(\"Dice_US_jobs_Clean_v4.csv\", encoding=\"cp437\")\n",
    "print(f\"No of rows in Dice_us_jobs_dataset is {Dice_us_jobs_dataset.shape[0]}\")\n",
    "\n",
    "monster_dataset = pd.read_csv(\"Monster_Clean.csv\")\n",
    "print(f\"No of rows in monster_dataset is {monster_dataset.shape[0]}\")\n",
    "\n",
    "indeed_dataset = pd.read_csv(\"alldata_Clean_v3.csv\")\n",
    "print(f\"No of rows in indeed_dataset is {indeed_dataset.shape[0]}\")\n",
    "\n",
    "##file needs to match format for concat\n",
    "dice_tech_filtered = pd.read_csv(\"Dice_US_Tech_FilteredJobData.csv\")\n",
    "print(f\"No of rows in dice_tech_filtered is {dice_tech_filtered.shape[0]}\")\n",
    "\n",
    "print(f\"No of rows in final merged data set should be {Aijobsindustry_dataset.shape[0]+Dice_us_jobs_dataset.shape[0]+monster_dataset.shape[0]+indeed_dataset.shape[0]+dice_tech_filtered.shape[0]}\")\n",
    "\n",
    "datasets_to_merge = [Aijobsindustry_dataset,Dice_us_jobs_dataset,monster_dataset,indeed_dataset,dice_tech_filtered]\n",
    "\n",
    "##please confirm the concat makes sense\n",
    "merged_dataset = pd.concat(datasets_to_merge)\n",
    "print(f\"Actual no of rows in merged_dataset is {merged_dataset.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(column):\n",
    "    word_count = {}\n",
    "    for entry in column:\n",
    "        entry = (re.sub('[^A-Za-z0-9 ]+', '', str(entry))).lower()\n",
    "        try:\n",
    "            entry = entry.replace(',','')\n",
    "            word_split = entry.split()\n",
    "            for word in word_split:\n",
    "                if word not in word_count:\n",
    "                    word_count[word] = 1\n",
    "                else:\n",
    "                    word_count[word] += 1\n",
    "        except AttributeError:\n",
    "            print(\"Skipping an entry due to bad data\")\n",
    "            continue\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = merged_dataset['Description']\n",
    "parsed_data = parser(desc)\n",
    "#print(parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4206\n"
     ]
    }
   ],
   "source": [
    "print(parsed_data['python'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loc_state\n",
       "AL     2\n",
       "CA    11\n",
       "CO     1\n",
       "DC     1\n",
       "DE     1\n",
       "FL     4\n",
       "GA     7\n",
       "IL     4\n",
       "IN     2\n",
       "KS     2\n",
       "LA     2\n",
       "MA     6\n",
       "MD     1\n",
       "ME     1\n",
       "MN     2\n",
       "NC     4\n",
       "NE     2\n",
       "NJ     3\n",
       "NV     3\n",
       "NY     7\n",
       "OH    28\n",
       "OK     1\n",
       "PA     4\n",
       "SC     2\n",
       "TX    33\n",
       "VA     3\n",
       "WA     3\n",
       "WI     4\n",
       "Name: Position, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_by_state = monster_dataset.groupby(\"Loc_state\")\n",
    "count_for_state = group_by_state.count()\n",
    "count_for_state = count_for_state[\"Position\"]\n",
    "count_for_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
