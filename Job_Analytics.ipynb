{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "# import gmplot\n",
    "# from geopy.geocoders import Nominatim\n",
    "# import time\n",
    "# import gmaps\n",
    "# import gmaps.datasets\n",
    "\n",
    "Aijobsindustry_dataset = pd.read_csv(\"AIJobsIndustry_Clean_v3.csv\")\n",
    "print(f\"No of rows in Aijobsindustry_dataset is {Aijobsindustry_dataset.shape[0]}\")\n",
    "\n",
    "Dice_us_jobs_dataset = pd.read_csv(\"Dice_US_jobs_Clean_v2.csv\", encoding=\"cp437\")\n",
    "print(f\"No of rows in Dice_us_jobs_dataset is {Dice_us_jobs_dataset.shape[0]}\")\n",
    "\n",
    "monster_dataset = pd.read_csv(\"Monster_Clean.csv\")\n",
    "print(f\"No of rows in monster_dataset is {monster_dataset.shape[0]}\")\n",
    "\n",
    "indeed_dataset = pd.read_csv(\"alldata_Clean_v2.csv\")\n",
    "print(f\"No of rows in indeed_dataset is {indeed_dataset.shape[0]}\")\n",
    "\n",
    "##file needs to match format for concat\n",
    "# Dice_use_Tech_filtered = pd.read_csv(\"Dice_US_Tech_FilteredJobData.csv\")\n",
    "# Dice_use_Tech_filtered\n",
    "\n",
    "print(f\"No of rows in final merged data set should be is {Aijobsindustry_dataset.shape[0]+Dice_us_jobs_dataset.shape[0]+monster_dataset.shape[0]+indeed_dataset.shape[0]}\")\n",
    "\n",
    "datasets_to_merge = [Aijobsindustry_dataset,Dice_us_jobs_dataset,monster_dataset,indeed_dataset]\n",
    "\n",
    "##please confirm the concat makes sense\n",
    "merged_dataset = pd.concat(datasets_to_merge)\n",
    "print(f\"Actual no of rows in merged_dataset is {merged_dataset.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(column):\n",
    "    word_count = {}\n",
    "    for entry in column:\n",
    "        entry = re.sub('[^A-Za-z0-9 ]+', '', str(entry))\n",
    "#        print(entry)\n",
    "        try:\n",
    "            entry = entry.replace(',','')\n",
    "            word_split = entry.split()\n",
    "            for word in word_split:\n",
    "                if word not in word_count:\n",
    "                    word_count[word] = 1\n",
    "                else:\n",
    "                    word_count[word] += 1\n",
    "        except AttributeError:\n",
    "            print(\"Skipping an entry due to bad data\")\n",
    "            continue\n",
    "    print(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = merged_dataset['Description']\n",
    "parser(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_state = monster_dataset.groupby(\"Loc_state\")\n",
    "count_for_state = group_by_state.count()\n",
    "count_for_state = count_for_state[\"Position\"]\n",
    "count_for_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
